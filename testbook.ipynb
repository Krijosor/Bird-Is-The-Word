{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a667ce85",
   "metadata": {},
   "source": [
    "### Test of data instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21443577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import matplotlib as plt\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from src import BWDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa415b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\legom\\anaconda3\\envs\\birdword\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\legom\\anaconda3\\envs\\birdword\\Lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_doc_ori), the model files will be automatically downloaded and saved in C:\\Users\\legom\\.paddlex\\official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 3727.72it/s]\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mUsing official model (UVDoc), the model files will be automatically downloaded and saved in C:\\Users\\legom\\.paddlex\\official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 1346.27it/s]\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_textline_ori), the model files will be automatically downloaded and saved in C:\\Users\\legom\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_det), the model files will be automatically downloaded and saved in C:\\Users\\legom\\.paddlex\\official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 1864.55it/s]\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_rec', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_rec), the model files will be automatically downloaded and saved in C:\\Users\\legom\\.paddlex\\official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 3309.99it/s]\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR as POCR\n",
    "\n",
    "ocr = POCR(lang=\"en\", use_doc_orientation_classify=True, use_doc_unwarping=True, use_textline_orientation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701cb823",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"dataset/datasets/rf/ringcodes.csv\"\n",
    "image_path = \"dataset/datasets/rf/images\"\n",
    "max_n = 10\n",
    "transform = T.Compose([\n",
    "    #T.Resize((224,224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "exp_dataset = BWDatasets.TrainDataSet(img_path=image_path, labels_path=label_path, transform=transform, max_n=max_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be74668",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# img_crop = F.crop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b48d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 0.521075 0.558316 0.0353341 0.104376 0.83813\n",
    "\n",
    "def calculate_bb_cords(image, bb):\n",
    "    bb_x = image.shape[2] * float(bb[1])\n",
    "    bb_y = image.shape[1] * float(bb[2])\n",
    "    bb_w = image.shape[2] * float(bb[3])\n",
    "    bb_h = image.shape[1] * float(bb[4])\n",
    "\n",
    "    return bb_x, bb_y, bb_w, bb_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57a2ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_txt_to_list(bb_path):\n",
    "    \n",
    "    with open(bb_path) as f:\n",
    "        line = f.readline().strip()\n",
    "\n",
    "        bb = line.split(' ')\n",
    "    \n",
    "    return bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5b40e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0.521075', '0.558316', '0.0353341', '0.104376', '0.83813']\n"
     ]
    }
   ],
   "source": [
    "img, l = exp_dataset[0]\n",
    "bb_path = \"dataset/datasets/rf/labels/20240408-145102.064779(162.29,-4.57,9209.0).txt\"\n",
    "bb = bb_txt_to_list(bb_path)\n",
    "print(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fc5c276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000.4639999999999, 602.9812800000001, 67.841472, 112.72608)\n"
     ]
    }
   ],
   "source": [
    "img, l = exp_dataset[0]\n",
    "\n",
    "bb_cords = calculate_bb_cords(img, bb)\n",
    "\n",
    "print(bb_cords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c628614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_uint8 = (img * 255).to(torch.uint8)\n",
    "\n",
    "# 2) prepare your box(es): tensor of shape (num_boxes, 4) in (xmin, ymin, xmax, ymax)\n",
    "boxes = torch.tensor([[bb_cords[0], bb_cords[1], bb_cords[0]+bb_cords[2], bb_cords[1]+bb_cords[3]]], dtype=torch.int)\n",
    "\n",
    "# 4) draw\n",
    "img_boxes = draw_bounding_boxes(\n",
    "    img_uint8,\n",
    "    boxes,\n",
    "    labels=labels,\n",
    "    colors=\"red\",\n",
    "    width=2\n",
    ")\n",
    "\n",
    "# 5) convert back to PIL or plot with matplotlib\n",
    "plt.imshow(img_boxes)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab310a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp_loader = DataLoader(dataset=exp_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdb1a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(dataloader):\n",
    "    for images, labels in dataloader:\n",
    "        images = BWDatasets.tensor_to_numpy(images)\n",
    "        labels = labels[0]\n",
    "        for i, image in enumerate(images):\n",
    "            result = ocr.predict(image)\n",
    "\n",
    "            print(\"-------------------\")\n",
    "            print(f'Prediction: {result[0][\"rec_texts\"]}')\n",
    "            print(f'Actual: {labels[i]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4191811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Prediction: []\n",
      "Actual: JJ94C\n",
      "-------------------\n",
      "Prediction: ['']\n",
      "Actual: JE24X\n",
      "-------------------\n",
      "Prediction: []\n",
      "Actual: JE25X\n",
      "-------------------\n",
      "Prediction: []\n",
      "Actual: JJ89C\n",
      "-------------------\n",
      "Prediction: []\n",
      "Actual: J808V\n",
      "-------------------\n",
      "Prediction: []\n",
      "Actual: J194V\n",
      "-------------------\n",
      "Prediction: []\n",
      "Actual: JE24X\n",
      "-------------------\n",
      "Prediction: []\n",
      "Actual: JJ94C\n",
      "-------------------\n",
      "Prediction: []\n",
      "Actual: JE94C\n",
      "-------------------\n",
      "Prediction: []\n",
      "Actual: JE24X\n"
     ]
    }
   ],
   "source": [
    "prediction(exp_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4f95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c51f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d954f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdword",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
